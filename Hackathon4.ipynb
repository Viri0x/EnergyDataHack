{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dbh6ShYTYMFa"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "W-plhOKoYPjv"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "%tensorflow_version 2.x\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import numpy as np\n",
    "import time\n",
    "import matplotlib\n",
    "from plot_keras_history import plot_history\n",
    "\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rKFpT9j5YU0g"
   },
   "outputs": [],
   "source": [
    "def read_int(f):\n",
    "    ba = bytearray(4)\n",
    "    f.readinto(ba)\n",
    "    prm = np.frombuffer(ba, dtype=np.int32)\n",
    "    return prm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CFf_XcPDYWJo"
   },
   "outputs": [],
   "source": [
    "def read_double(f):\n",
    "    ba = bytearray(8)\n",
    "    f.readinto(ba)\n",
    "    prm = np.frombuffer(ba, dtype=np.double)\n",
    "    return prm[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HG6rEf03YXlP"
   },
   "outputs": [],
   "source": [
    "def read_double_tab(f, n):\n",
    "    ba = bytearray(8*n)\n",
    "    nr = f.readinto(ba)\n",
    "    if nr != len(ba):\n",
    "        return []\n",
    "    else:\n",
    "        prm = np.frombuffer(ba, dtype=np.double)\n",
    "        return prm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zf3g_F_XYZKg"
   },
   "outputs": [],
   "source": [
    "def get_pics_from_file(filename):\n",
    "    # Lecture du fichier d'infos + pics detectes (post-processing KeyFinder)\n",
    "    f_pic = open(filename, \"rb\")\n",
    "    info = dict()\n",
    "    info[\"nb_pics\"] = read_int(f_pic)\n",
    "    info[\"freq_sampling_khz\"] = read_double(f_pic)\n",
    "    info[\"freq_trame_hz\"] = read_double(f_pic)\n",
    "    info[\"freq_pic_khz\"] = read_double(f_pic)\n",
    "    info[\"norm_fact\"] = read_double(f_pic)\n",
    "    tab_pics = []\n",
    "    pics = read_double_tab(f_pic, info[\"nb_pics\"])\n",
    "    nb_trames = 1\n",
    "    while len(pics) > 0:\n",
    "        nb_trames = nb_trames+1\n",
    "        tab_pics.append(pics)\n",
    "        pics = read_double_tab(f_pic, info[\"nb_pics\"])\n",
    "    f_pic.close()\n",
    "    return tab_pics, info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IHxuPxrLYyT4",
    "outputId": "41d59f5e-5efd-40ae-e369-db4b8793b1ce"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', '1', '2', '4', '3', '5', '6', '7', '8', '9', 'B', 'C', 'A', 'CTRL', 'E', 'D', 'ENTER', 'F', 'G', 'I', 'L', 'J', 'H', 'M', 'NOKEY', 'N', 'K', 'Y', 'U', 'Q', 'Z', 'SUPPR', 'V', 'T', 'O', 'R', 'SPACE', 'P', 'W', 'X', 'SHIFT', 'S']\n"
     ]
    }
   ],
   "source": [
    "# Creating lists for data\n",
    "# frames : all frames\n",
    "# letters : letter correspondig to frames\n",
    "import os\n",
    "\n",
    "nb = 0\n",
    "frames = []\n",
    "letters = []\n",
    "labl = []\n",
    "for file in os.listdir(\"data\"):\n",
    "  pics, info = get_pics_from_file(\"data/\" + file)\n",
    "  label = file.split('_')[1]\n",
    "  label = label.split(\".\")[0]\n",
    "  if (label == \"LOGINMDP\"):\n",
    "    continue\n",
    "  labl.append(label)\n",
    "  frames.extend(pics)\n",
    "  letters.extend([label] * len(pics))\n",
    "\n",
    "print(labl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jXJW3InFsq0D",
    "outputId": "392191e5-16e0-43fa-ed52-b747d0c63cc4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "246128\n",
      "246128\n",
      "52742\n",
      "52742\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(frames, letters, train_size=0.7, random_state=42, stratify=letters)\n",
    "\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_test, y_test, train_size=0.5, random_state=42, stratify=y_test)\n",
    "print(len(X_train))\n",
    "print(len(y_train))\n",
    "print(len(y_test))\n",
    "print(len(y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "c0SClTe_C7o4",
    "outputId": "0f3f1515-0694-4366-ecb3-405100be1365"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.39.221.42:8470\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Initializing the TPU system: grpc://10.39.221.42:8470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Clearing out eager caches\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Finished initializing TPU system.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All devices:  [LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:7', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:6', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:5', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:4', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:3', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:0', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:1', device_type='TPU'), LogicalDevice(name='/job:worker/replica:0/task:0/device:TPU:2', device_type='TPU')]\n",
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Found TPU system:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Workers: 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Num TPU Cores Per Worker: 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:localhost/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 0, 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:*** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 0, 0)\n"
     ]
    }
   ],
   "source": [
    "## USING TPU ON GOOGLE COLAB\n",
    "\n",
    "resolver = tf.distribute.cluster_resolver.TPUClusterResolver(tpu='')\n",
    "tf.config.experimental_connect_to_cluster(resolver)\n",
    "# This is the TPU initialization code that has to be at the beginning.\n",
    "tf.tpu.experimental.initialize_tpu_system(resolver)\n",
    "print(\"All devices: \", tf.config.list_logical_devices('TPU'))\n",
    "\n",
    "strategy = tf.distribute.TPUStrategy(resolver)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HC7C8ZLg2Cs1"
   },
   "source": [
    "RESNET MODEL that we took from: https://github.com/hfawaz/dl-4-tsc/blob/master/classifiers/resnet.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vl0pVmZX2Icd"
   },
   "outputs": [],
   "source": [
    "# resnet model \n",
    "# when tuning start with learning rate->mini_batch_size -> \n",
    "# momentum-> #hidden_units -> # learning_rate_decay -> #layers \n",
    "import tensorflow.keras as keras\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.use('agg')\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "class Classifier_RESNET:\n",
    "\n",
    "    def __init__(self, output_directory, input_shape, nb_classes, verbose=False, build=True, load_weights=False):\n",
    "        self.output_directory = output_directory\n",
    "        if build == True:\n",
    "          ## USING STRATEGY ON GOOGLE COLAB\n",
    "          with strategy.scope():\n",
    "            self.model = self.build_model(input_shape, nb_classes)\n",
    "            if (verbose == True):\n",
    "                self.model.summary()\n",
    "            self.verbose = verbose\n",
    "            if load_weights == True:\n",
    "                self.model.load_weights(self.output_directory\n",
    "                                        .replace('resnet_augment', 'resnet')\n",
    "                                        .replace('TSC_itr_augment_x_10', 'TSC_itr_10')\n",
    "                                        + '/model_init.hdf5')\n",
    "            else:\n",
    "                self.model.save_weights(self.output_directory + 'model_init.hdf5')\n",
    "        return\n",
    "\n",
    "    def build_model(self, input_shape, nb_classes):\n",
    "        n_feature_maps = 64\n",
    "\n",
    "        input_layer = keras.layers.Input(input_shape)\n",
    "\n",
    "        # BLOCK 1\n",
    "\n",
    "        conv_x = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=8, padding='same')(input_layer)\n",
    "        conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "        conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "\n",
    "        conv_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=5, padding='same')(conv_x)\n",
    "        conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "        conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "\n",
    "        conv_z = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=3, padding='same')(conv_y)\n",
    "        conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "        # expand channels for the sum\n",
    "        shortcut_y = keras.layers.Conv1D(filters=n_feature_maps, kernel_size=1, padding='same')(input_layer)\n",
    "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "        output_block_1 = keras.layers.add([shortcut_y, conv_z])\n",
    "        output_block_1 = keras.layers.Activation('relu')(output_block_1)\n",
    "\n",
    "        # BLOCK 2\n",
    "\n",
    "        conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_1)\n",
    "        conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "        conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "\n",
    "        conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
    "        conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "        conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "\n",
    "        conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
    "        conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "        # expand channels for the sum\n",
    "        shortcut_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=1, padding='same')(output_block_1)\n",
    "        shortcut_y = keras.layers.BatchNormalization()(shortcut_y)\n",
    "\n",
    "        output_block_2 = keras.layers.add([shortcut_y, conv_z])\n",
    "        output_block_2 = keras.layers.Activation('relu')(output_block_2)\n",
    "\n",
    "        # BLOCK 3\n",
    "\n",
    "        conv_x = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=8, padding='same')(output_block_2)\n",
    "        conv_x = keras.layers.BatchNormalization()(conv_x)\n",
    "        conv_x = keras.layers.Activation('relu')(conv_x)\n",
    "\n",
    "        conv_y = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=5, padding='same')(conv_x)\n",
    "        conv_y = keras.layers.BatchNormalization()(conv_y)\n",
    "        conv_y = keras.layers.Activation('relu')(conv_y)\n",
    "\n",
    "        conv_z = keras.layers.Conv1D(filters=n_feature_maps * 2, kernel_size=3, padding='same')(conv_y)\n",
    "        conv_z = keras.layers.BatchNormalization()(conv_z)\n",
    "\n",
    "        # no need to expand channels because they are equal\n",
    "        shortcut_y = keras.layers.BatchNormalization()(output_block_2)\n",
    "\n",
    "        output_block_3 = keras.layers.add([shortcut_y, conv_z])\n",
    "        output_block_3 = keras.layers.Activation('relu')(output_block_3)\n",
    "\n",
    "        # FINAL\n",
    "\n",
    "        gap_layer = keras.layers.GlobalAveragePooling1D()(output_block_3)\n",
    "\n",
    "        output_layer = keras.layers.Dense(nb_classes, activation='softmax')(gap_layer)\n",
    "\n",
    "        model = keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
    "        ## USING STRATEGY ON GOOGLE COLAB\n",
    "        with strategy.scope():\n",
    "          model.compile(loss='categorical_crossentropy', optimizer=keras.optimizers.Adam(),\n",
    "                      metrics=['accuracy'])\n",
    "\n",
    "        reduce_lr = keras.callbacks.ReduceLROnPlateau(monitor='loss', factor=0.5, patience=50, min_lr=0.0001)\n",
    "\n",
    "        file_path = self.output_directory + 'best_model.hdf5'\n",
    "\n",
    "        model_checkpoint = keras.callbacks.ModelCheckpoint(filepath=file_path, monitor='loss',\n",
    "                                                            save_best_only=True)\n",
    "\n",
    "        self.callbacks = [reduce_lr, model_checkpoint]\n",
    "\n",
    "        return model\n",
    "\n",
    "    def fit(self, x_train, y_train, x_val, y_val, y_true):\n",
    "        if not tf.test.is_gpu_available:\n",
    "            print('error')\n",
    "            exit()\n",
    "        # x_val and y_val are only used to monitor the test loss and NOT for training\n",
    "        batch_size = 64\n",
    "        nb_epochs = 1500\n",
    "\n",
    "        mini_batch_size = int(min(x_train.shape[0] / 10, batch_size))\n",
    "\n",
    "        start_time = time.time()\n",
    "\n",
    "        hist = self.model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=nb_epochs,\n",
    "                              verbose=self.verbose, validation_data=(x_val, y_val), callbacks=self.callbacks)\n",
    "\n",
    "        duration = time.time() - start_time\n",
    "\n",
    "        self.model.save(self.output_directory + 'last_model.hdf5')\n",
    "\n",
    "        y_pred = self.predict(x_val, y_true, x_train, y_train, y_val,\n",
    "                              return_df_metrics=False)\n",
    "\n",
    "        # save predictions\n",
    "        np.save(self.output_directory + 'y_pred.npy', y_pred)\n",
    "\n",
    "        # convert the predicted from binary to integer\n",
    "        y_pred = np.argmax(y_pred, axis=1)\n",
    "\n",
    "        df_metrics = save_logs(self.output_directory, hist, y_pred, y_true, duration)\n",
    "\n",
    "        keras.backend.clear_session()\n",
    "\n",
    "        return df_metrics\n",
    "\n",
    "    def predict(self, x_test, y_true, x_train, y_train, y_test):\n",
    "        start_time = time.time()\n",
    "        model_path = self.output_directory + 'best_model.hdf5'\n",
    "        model = keras.models.load_model(model_path)\n",
    "        y_pred = model.predict(x_test)\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8qfvXU1K2OKv"
   },
   "outputs": [],
   "source": [
    "# Formatting the input for the resnet (one hot encoding, reshape ...)\n",
    "\n",
    "import sklearn\n",
    "\n",
    "X_train = np.asarray(X_train)\n",
    "X_test = np.asarray(X_test)\n",
    "y_train = np.asarray(y_train)\n",
    "y_test = np.asarray(y_test)\n",
    "X_val = np.asarray(X_val)\n",
    "y_val = np.asarray(y_val)\n",
    "\n",
    "enc = sklearn.preprocessing.OneHotEncoder(categories='auto')\n",
    "enc.fit(np.concatenate((y_train, y_test), axis=0).reshape(-1, 1))\n",
    "y_train = enc.transform(y_train.reshape(-1, 1)).toarray()\n",
    "y_test = enc.transform(y_test.reshape(-1, 1)).toarray()\n",
    "y_val = enc.transform(y_val.reshape(-1, 1)).toarray()\n",
    "\n",
    "if len(X_train.shape) == 2:  # if univariate\n",
    "    # add a dimension to make it multivariate with one dimension \n",
    "    X_train = X_train.reshape((X_train.shape[0], X_train.shape[1], 1))\n",
    "    X_test = X_test.reshape((X_test.shape[0], X_test.shape[1], 1))\n",
    "    X_val = X_val.reshape((X_val.shape[0], X_val.shape[1], 1))\n",
    "\n",
    "y_true = np.argmax(y_test, axis=1)\n",
    "input_shape = X_train.shape[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "J08Bxx8gAlI8"
   },
   "outputs": [],
   "source": [
    "model = Classifier_RESNET(\"hackaton_output\", input_shape=input_shape, nb_classes=len(labl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "hfkjaZv74xg1",
    "outputId": "8d68eff7-c047-4c8b-f812-ee22e281173d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2000\n",
      "15383/15383 [==============================] - 236s 15ms/step - loss: 1.4304 - accuracy: 0.4559 - val_loss: 0.9392 - val_accuracy: 0.5433\n",
      "Epoch 2/2000\n",
      "15383/15383 [==============================] - 228s 15ms/step - loss: 0.9871 - accuracy: 0.5256 - val_loss: 0.9757 - val_accuracy: 0.5325\n",
      "Epoch 3/2000\n",
      "15383/15383 [==============================] - 227s 15ms/step - loss: 0.9571 - accuracy: 0.5343 - val_loss: 0.9439 - val_accuracy: 0.5456\n",
      "Epoch 4/2000\n",
      "15383/15383 [==============================] - 224s 15ms/step - loss: 0.9448 - accuracy: 0.5384 - val_loss: 0.9598 - val_accuracy: 0.5461\n",
      "Epoch 5/2000\n",
      "15383/15383 [==============================] - 222s 14ms/step - loss: 0.9359 - accuracy: 0.5408 - val_loss: 0.9459 - val_accuracy: 0.5531\n",
      "Epoch 6/2000\n",
      "15383/15383 [==============================] - 214s 14ms/step - loss: 0.9289 - accuracy: 0.5431 - val_loss: 0.9362 - val_accuracy: 0.5491\n",
      "Epoch 7/2000\n",
      "15383/15383 [==============================] - 211s 14ms/step - loss: 0.9246 - accuracy: 0.5462 - val_loss: 0.9505 - val_accuracy: 0.5481\n",
      "Epoch 8/2000\n",
      "15383/15383 [==============================] - 211s 14ms/step - loss: 0.9150 - accuracy: 0.5486 - val_loss: 0.9522 - val_accuracy: 0.5561\n",
      "Epoch 9/2000\n",
      "15383/15383 [==============================] - 211s 14ms/step - loss: 0.9157 - accuracy: 0.5488 - val_loss: 0.9118 - val_accuracy: 0.5615\n",
      "Epoch 10/2000\n",
      "15383/15383 [==============================] - 211s 14ms/step - loss: 0.9112 - accuracy: 0.5527 - val_loss: 0.9665 - val_accuracy: 0.5447\n",
      "Epoch 11/2000\n",
      "15383/15383 [==============================] - 213s 14ms/step - loss: 0.9092 - accuracy: 0.5531 - val_loss: 0.9620 - val_accuracy: 0.5622\n",
      "Epoch 12/2000\n",
      "15383/15383 [==============================] - 211s 14ms/step - loss: 0.9076 - accuracy: 0.5560 - val_loss: 0.9443 - val_accuracy: 0.5629\n",
      "Epoch 13/2000\n",
      "15383/15383 [==============================] - 210s 14ms/step - loss: 0.9082 - accuracy: 0.5538 - val_loss: 0.9734 - val_accuracy: 0.5482\n",
      "Epoch 14/2000\n",
      "15383/15383 [==============================] - 209s 14ms/step - loss: 0.9019 - accuracy: 0.5577 - val_loss: 0.9303 - val_accuracy: 0.5517\n",
      "Epoch 15/2000\n",
      "15383/15383 [==============================] - 210s 14ms/step - loss: 0.8983 - accuracy: 0.5581 - val_loss: 0.9128 - val_accuracy: 0.5632\n",
      "Epoch 16/2000\n",
      "15383/15383 [==============================] - 211s 14ms/step - loss: 0.8980 - accuracy: 0.5580 - val_loss: 0.9299 - val_accuracy: 0.5559\n",
      "Epoch 17/2000\n",
      "15383/15383 [==============================] - 212s 14ms/step - loss: 0.8964 - accuracy: 0.5623 - val_loss: 0.9066 - val_accuracy: 0.5629\n",
      "Epoch 18/2000\n",
      "15383/15383 [==============================] - 211s 14ms/step - loss: 0.8956 - accuracy: 0.5641 - val_loss: 0.9342 - val_accuracy: 0.5613\n",
      "Epoch 19/2000\n",
      "15383/15383 [==============================] - 211s 14ms/step - loss: 0.8924 - accuracy: 0.5638 - val_loss: 0.9047 - val_accuracy: 0.5619\n",
      "Epoch 20/2000\n",
      "15383/15383 [==============================] - 216s 14ms/step - loss: 0.8918 - accuracy: 0.5655 - val_loss: 0.9008 - val_accuracy: 0.5666\n",
      "Epoch 21/2000\n",
      "15383/15383 [==============================] - 215s 14ms/step - loss: 0.8921 - accuracy: 0.5665 - val_loss: 0.9234 - val_accuracy: 0.5631\n",
      "Epoch 22/2000\n",
      "15383/15383 [==============================] - 215s 14ms/step - loss: 0.8890 - accuracy: 0.5677 - val_loss: 0.9385 - val_accuracy: 0.5561\n",
      "Epoch 23/2000\n",
      "15383/15383 [==============================] - 215s 14ms/step - loss: 0.8818 - accuracy: 0.5709 - val_loss: 0.9074 - val_accuracy: 0.5669\n",
      "Epoch 24/2000\n",
      "15383/15383 [==============================] - 217s 14ms/step - loss: 0.8848 - accuracy: 0.5712 - val_loss: 0.9902 - val_accuracy: 0.5363\n",
      "Epoch 25/2000\n",
      "15383/15383 [==============================] - 215s 14ms/step - loss: 0.8823 - accuracy: 0.5710 - val_loss: 0.9170 - val_accuracy: 0.5640\n",
      "Epoch 26/2000\n",
      "15383/15383 [==============================] - 220s 14ms/step - loss: 0.8782 - accuracy: 0.5731 - val_loss: 0.9068 - val_accuracy: 0.5653\n",
      "Epoch 27/2000\n",
      "15383/15383 [==============================] - 226s 15ms/step - loss: 0.8799 - accuracy: 0.5726 - val_loss: 0.9044 - val_accuracy: 0.5636\n",
      "Epoch 28/2000\n",
      "15383/15383 [==============================] - 229s 15ms/step - loss: 0.8749 - accuracy: 0.5762 - val_loss: 0.9094 - val_accuracy: 0.5647\n",
      "Epoch 29/2000\n",
      "15383/15383 [==============================] - 226s 15ms/step - loss: 0.8717 - accuracy: 0.5784 - val_loss: 0.9190 - val_accuracy: 0.5695\n",
      "Epoch 30/2000\n",
      "15383/15383 [==============================] - 217s 14ms/step - loss: 0.8732 - accuracy: 0.5777 - val_loss: 0.9158 - val_accuracy: 0.5658\n",
      "Epoch 31/2000\n",
      "15383/15383 [==============================] - 223s 15ms/step - loss: 0.8685 - accuracy: 0.5816 - val_loss: 0.9537 - val_accuracy: 0.5498\n",
      "Epoch 32/2000\n",
      "15383/15383 [==============================] - 222s 14ms/step - loss: 0.8696 - accuracy: 0.5802 - val_loss: 0.9195 - val_accuracy: 0.5641\n",
      "Epoch 33/2000\n",
      "15383/15383 [==============================] - 238s 15ms/step - loss: 0.8686 - accuracy: 0.5816 - val_loss: 0.9089 - val_accuracy: 0.5668\n",
      "Epoch 34/2000\n",
      "15383/15383 [==============================] - 244s 16ms/step - loss: 0.8668 - accuracy: 0.5821 - val_loss: 0.9254 - val_accuracy: 0.5662\n",
      "Epoch 35/2000\n",
      "15383/15383 [==============================] - 233s 15ms/step - loss: 0.8664 - accuracy: 0.5826 - val_loss: 0.9093 - val_accuracy: 0.5666\n",
      "Epoch 36/2000\n",
      "15383/15383 [==============================] - 232s 15ms/step - loss: 0.8629 - accuracy: 0.5846 - val_loss: 0.9173 - val_accuracy: 0.5650\n",
      "Epoch 37/2000\n",
      "15383/15383 [==============================] - 243s 16ms/step - loss: 0.8611 - accuracy: 0.5889 - val_loss: 0.9308 - val_accuracy: 0.5653\n",
      "Epoch 38/2000\n",
      "15383/15383 [==============================] - 265s 17ms/step - loss: 0.8609 - accuracy: 0.5887 - val_loss: 0.9337 - val_accuracy: 0.5589\n",
      "Epoch 39/2000\n",
      "15383/15383 [==============================] - 253s 16ms/step - loss: 0.8609 - accuracy: 0.5871 - val_loss: 0.9378 - val_accuracy: 0.5598\n",
      "Epoch 40/2000\n",
      "15383/15383 [==============================] - 247s 16ms/step - loss: 0.8595 - accuracy: 0.5892 - val_loss: 0.9626 - val_accuracy: 0.5463\n",
      "Epoch 41/2000\n",
      "15383/15383 [==============================] - 253s 16ms/step - loss: 0.8573 - accuracy: 0.5899 - val_loss: 0.9066 - val_accuracy: 0.5650\n",
      "Epoch 42/2000\n",
      "15383/15383 [==============================] - 257s 17ms/step - loss: 0.8550 - accuracy: 0.5907 - val_loss: 0.9149 - val_accuracy: 0.5650\n",
      "Epoch 43/2000\n",
      "15383/15383 [==============================] - 250s 16ms/step - loss: 0.8555 - accuracy: 0.5923 - val_loss: 0.9865 - val_accuracy: 0.5488\n",
      "Epoch 44/2000\n",
      "15383/15383 [==============================] - 249s 16ms/step - loss: 0.8545 - accuracy: 0.5931 - val_loss: 0.9303 - val_accuracy: 0.5619\n",
      "Epoch 45/2000\n",
      "11685/15383 [=====================>........] - ETA: 50s - loss: 0.8487 - accuracy: 0.5975"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-60346daf1602>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-12-c76c1965e471>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x_train, y_train, x_val, y_val, y_true)\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m     hist = self.model.fit(x_train, y_train, batch_size=mini_batch_size, epochs=nb_epochs,\n\u001b[0;32m---> 72\u001b[0;31m       verbose=1, validation_data=(x_val,y_val), callbacks=self.callbacks)\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0mduration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3312\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0margs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3313\u001b[0m       \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3314\u001b[0;31m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_spec\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize_function_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3315\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3316\u001b[0m       \u001b[0mflat_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcanonicalize_function_inputs\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2695\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2696\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_input_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2697\u001b[0;31m       \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_numpy_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2698\u001b[0m       \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflat_kwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_kwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_convert_numpy_inputs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2699\u001b[0m       return (inputs, kwargs, flat_inputs + flat_kwargs,\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_convert_numpy_inputs\u001b[0;34m(inputs)\u001b[0m\n\u001b[1;32m   2735\u001b[0m   \u001b[0;31m# are eventually passed to ConcreteFunction()._call_flat, which requires\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2736\u001b[0m   \u001b[0;31m# expanded composites.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2737\u001b[0;31m   \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2738\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2739\u001b[0m   \u001b[0;31m# Check for NumPy arrays in arguments and convert them to Tensors.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    339\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    340\u001b[0m   \u001b[0mexpand_composites\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 341\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    342\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py\u001b[0m in \u001b[0;36m_type_spec\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1790\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_type_spec\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1791\u001b[0m     return _SingleWorkerDatasetIteratorSpec(self._worker, self._devices,\n\u001b[0;32m-> 1792\u001b[0;31m                                             self._element_spec, self._options)\n\u001b[0m\u001b[1;32m   1793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1794\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, worker, devices, element_spec, options)\u001b[0m\n\u001b[1;32m   1679\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_devices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/input_lib.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1679\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melement_spec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1680\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_worker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1681\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_devices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_util\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcanonicalize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1682\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_element_spec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0melement_spec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1683\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_options\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/distribute/device_util.py\u001b[0m in \u001b[0;36mcanonicalize\u001b[0;34m(d, default)\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m       \u001b[0;31m# The default job is localhost if eager execution is enabled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 68\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"localhost\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     69\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mdefault\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \u001b[0;31m# Overrides any defaults with values from the default device if given.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/device_spec.py\u001b[0m in \u001b[0;36mreplace\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;31m# Explicitly provided kwargs take precedence.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0minit_kwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__class__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minit_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/device_spec.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, job, replica, task, device_type, device_index)\u001b[0m\n\u001b[1;32m    110\u001b[0m                \"_as_string\", \"_hash\")\n\u001b[1;32m    111\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m   def __init__(self, job=None, replica=None, task=None, device_type=None,\n\u001b[0m\u001b[1;32m    113\u001b[0m                device_index=None):\n\u001b[1;32m    114\u001b[0m     \"\"\"Create a new `DeviceSpec` object.\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Even after some tuning, the model ends up overfitting... maybe there is too much correlation in the data ?\n",
    "model.fit(X_train, y_train, X_val, y_val, y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6EmoMgIaXCDm"
   },
   "outputs": [],
   "source": [
    "loginmdp = []\n",
    "pics, info = get_pics_from_file(\"data/pics_LOGINMDP.bin\")\n",
    "loginmdp.extend(pics)\n",
    "\n",
    "loginmdp = np.asarray(loginmdp)\n",
    "loginmdp = loginmdp.reshape((loginmdp.shape[0], loginmdp.shape[1], 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RwkmIvxtaXh_"
   },
   "outputs": [],
   "source": [
    "pred = model.predict(loginmdp, y_true, X_train, y_train, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FQpwP7tAYdLw"
   },
   "outputs": [],
   "source": [
    "pswd = enc.inverse_transform(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Rj031fJcY57u"
   },
   "outputs": [],
   "source": [
    "pswd[100:]"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Hackathon4.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
